{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegram Channel Scraper\n",
    "\n",
    "This notebook scrapes messages from a list of specified Telegram channels and saves them into individual CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Install and Import Libraries\n",
    "\n",
    "First, ensure you have the necessary libraries installed. Then, import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (run this cell once)\n",
    "!pip install telethon python-dotenv asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from telethon import TelegramClient, events, sync, errors\n",
    "from telethon.tl.functions.messages import GetDialogsRequest\n",
    "from telethon.tl.types import InputPeerEmpty\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Optional: Configure logging for better debugging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Authentication\n",
    "\n",
    "Load API credentials and authenticate the Telegram client. You might need to enter a code sent to your Telegram account the first time you run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "api_id= \"YOUR_API_ID\"\n",
    "api_hash= \"YOUR_API_HASH\"\n",
    "phone= \"YOUR_PHONE_NUMBER_WITH_COUNTRY_CODE\"\n",
    "\n",
    "# Check if variables are loaded\n",
    "if not all([api_id, api_hash, phone]):\n",
    "    raise ValueError(\"Please ensure api_id, api_hash, and phone are set in your .env file.\")\n",
    "\n",
    "api_id = int(api_id) # Convert api_id to integer\n",
    "session_name = \"my_telegram_session\" # Use a unique session name \n",
    "\n",
    "# Create the client instance (asynchronous)\n",
    "client = TelegramClient(session_name, api_id, api_hash)\n",
    "\n",
    "async def authenticate_client():\n",
    "    \"\"\"Connects and authenticates the Telegram client.\"\"\"\n",
    "    print(\"Connecting to Telegram...\")\n",
    "    await client.connect()\n",
    "    \n",
    "    if not await client.is_user_authorized():\n",
    "        print(\"First time login or session expired. Sending code...\")\n",
    "        await client.send_code_request(phone)\n",
    "        try:\n",
    "            await client.sign_in(phone, input('Enter the code sent to your Telegram: '))\n",
    "            print(\"Signed in successfully!\")\n",
    "        except errors.SessionPasswordNeededError:\n",
    "            await client.sign_in(password=input('Two-step verification password needed: '))\n",
    "            print(\"Signed in successfully with 2FA!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during sign in: {e}\")\n",
    "            await client.disconnect()\n",
    "            raise # Reraise the exception to stop execution\n",
    "    else:\n",
    "        print(\"Client already authorized.\")\n",
    "    \n",
    "    # Verify connection\n",
    "    me = await client.get_me()\n",
    "    print(f\"Connected as: {me.first_name} (@{me.username})\")\n",
    "\n",
    "# Run the authentication (use await in a running asyncio loop, typical in Jupyter)\n",
    "# If you are in an environment without top-level await, you might need:\n",
    "# asyncio.run(authenticate_client())\n",
    "# But usually Jupyter/IPython handles the event loop.\n",
    "await authenticate_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Target Channel List\n",
    "\n",
    "Specify the path to your text file containing comma-separated channel usernames or links, and load them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_file_path = 'channels.txt' # <-- IMPORTANT: Update this path if needed\n",
    "channels = []\n",
    "\n",
    "try:\n",
    "    with open(seed_file_path, 'r', encoding='utf-8') as f:\n",
    "        # Read the whole file, remove potential leading/trailing whitespace,\n",
    "        # split by comma, and strip whitespace from each channel name.\n",
    "        raw_content = f.read().strip()\n",
    "        if raw_content: # Ensure file is not empty\n",
    "             channels = [name.strip() for name in raw_content.split(',') if name.strip()]\n",
    "    \n",
    "    if not channels:\n",
    "        print(f\"Warning: No channel names found or file is empty at {seed_file_path}\")\n",
    "    else:\n",
    "        print(f\"Loaded {len(channels)} channel(s) to scrape:\")\n",
    "        print(channels)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Seed file not found at '{seed_file_path}'. Please create it.\")\n",
    "    # Optionally create the directory structure if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(seed_file_path), exist_ok=True)\n",
    "    print(f\"Please create the file '{seed_file_path}' and add channel names, separated by commas.\")\n",
    "    channels = [] # Ensure channels list is empty if file not found\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the seed file: {e}\")\n",
    "    channels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Output Directory\n",
    "\n",
    "Define the directory where the scraped CSV files will be saved and create it if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'export/'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory '{output_dir}' ensured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scraping Logic\n",
    "\n",
    "Define the asynchronous function to iterate through the channels, fetch messages, and save them to CSV files. Includes error handling for inaccessible channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_channels(client, channel_list, output_directory):\n",
    "    \"\"\"Scrapes messages from a list of channels and saves them to CSV files.\"\"\"\n",
    "    \n",
    "    skipped_channels = []  # list to keep track of skipped channels\n",
    "    processed_channels = 0\n",
    "\n",
    "    if not await client.is_connected():\n",
    "       print(\"Client seems disconnected. Attempting to reconnect...\")\n",
    "       await authenticate_client() # Try to re-authenticate \n",
    "\n",
    "    # Define CSV headers\n",
    "    headers = [\n",
    "        'channel_name', 'message_id', 'peer_id', 'date', 'message_text', \n",
    "        'mentioned', 'is_post', 'from_id', 'fwd_from', 'reply_to_msg_id', \n",
    "        'media_type', 'entities', 'views', 'forwards', 'replies_count', \n",
    "        'edit_date', 'post_author', 'grouped_id', 'reactions' # Consider Reaction details if needed\n",
    "    ]\n",
    "\n",
    "    for channel_name in channel_list:\n",
    "        print(f\"\\n--- Processing channel: {channel_name} ---\")\n",
    "        try:\n",
    "            # Add a small delay to avoid hitting rate limits too quickly\n",
    "            await asyncio.sleep(2)\n",
    "            \n",
    "            # Resolve the channel entity (username, link, or ID)\n",
    "            try:\n",
    "                channel_entity = await client.get_entity(channel_name)\n",
    "                print(f\"Successfully found entity for {channel_name} (ID: {channel_entity.id})\")\n",
    "            except ValueError as ve:\n",
    "                 print(f\"Error resolving entity for '{channel_name}': {ve}. Might be an invalid username/link or not joined. Skipping.\")\n",
    "                 skipped_channels.append(channel_name)\n",
    "                 continue # Skip to the next channel\n",
    "            except errors.FloodWaitError as fwe:\n",
    "                 print(f\"Flood wait error for {channel_name}: waiting {fwe.seconds} seconds...\")\n",
    "                 await asyncio.sleep(fwe.seconds + 5) # Wait extra 5s\n",
    "                 channel_entity = await client.get_entity(channel_name) # Retry getting entity\n",
    "                 print(f\"Successfully found entity for {channel_name} after wait.\")\n",
    "            except Exception as ge:\n",
    "                 print(f\"Unexpected error getting entity for {channel_name}: {ge}. Skipping.\")\n",
    "                 skipped_channels.append(channel_name)\n",
    "                 continue\n",
    "\n",
    "            # Sanitize channel name for filename\n",
    "            safe_channel_name = \"\".join(c for c in channel_name if c.isalnum() or c in ('_', '-')).rstrip()\n",
    "            if not safe_channel_name:\n",
    "                safe_channel_name = f\"channel_{channel_entity.id}\" # Use ID if name is problematic\n",
    "                \n",
    "            output_file_path = os.path.join(output_directory, f\"{safe_channel_name}.csv\")\n",
    "            print(f\"Outputting to: {output_file_path}\")\n",
    "\n",
    "            message_count = 0\n",
    "            with open(output_file_path, \"w\", encoding='UTF-8', newline='') as f:\n",
    "                writer = csv.writer(f, delimiter=\",\", lineterminator=\"\\n\")\n",
    "                writer.writerow(headers)\n",
    "\n",
    "                # Iterate through messages (limit=None fetches all)\n",
    "                # Use a smaller limit for testing, e.g., limit=100\n",
    "                async for message in client.iter_messages(channel_entity, limit=None):\n",
    "                    # Extract data safely, providing defaults\n",
    "                    row_data = [\n",
    "                        channel_name, \n",
    "                        message.id,\n",
    "                        getattr(message.peer_id, 'channel_id', getattr(message.peer_id, 'chat_id', getattr(message.peer_id, 'user_id', ''))), # Get specific ID\n",
    "                        message.date.isoformat() if message.date else '', # Use ISO format for dates\n",
    "                        message.message if message.message else '',\n",
    "                        message.mentioned,\n",
    "                        message.post,\n",
    "                        getattr(message.from_id, 'user_id', '') if message.from_id else '', # Get user ID if possible\n",
    "                        str(message.fwd_from) if message.fwd_from else '', # Basic string representation\n",
    "                        message.reply_to.reply_to_msg_id if message.reply_to else '',\n",
    "                        type(message.media).__name__ if message.media else '', # Type of media\n",
    "                        str(message.entities) if message.entities else '', # Basic string representation\n",
    "                        message.views,\n",
    "                        message.forwards,\n",
    "                        message.replies.replies if message.replies else 0, # Get reply count\n",
    "                        message.edit_date.isoformat() if message.edit_date else '',\n",
    "                        message.post_author,\n",
    "                        message.grouped_id,\n",
    "                        str(message.reactions.results) if message.reactions else '' # Basic string representation of reactions\n",
    "                    ]\n",
    "                    writer.writerow(row_data)\n",
    "                    message_count += 1\n",
    "                    if message_count % 500 == 0:\n",
    "                        print(f\"  ... scraped {message_count} messages from {channel_name}\")\n",
    "            \n",
    "            print(f'Finished scraping {message_count} messages from {channel_name}. Data saved to {output_file_path}')\n",
    "            processed_channels += 1\n",
    "\n",
    "        except (errors.ChannelInvalidError, errors.ChannelPrivateError, errors.ChatAdminRequiredError, errors.UserNotParticipantError) as e:\n",
    "            print(f\"Access Error: Could not access channel '{channel_name}': {type(e).__name__} - {str(e)}. Skipping.\")\n",
    "            skipped_channels.append(channel_name)\n",
    "        except errors.FloodWaitError as e:\n",
    "            print(f\"Flood wait error for {channel_name}: waiting {e.seconds} seconds...\")\n",
    "            await asyncio.sleep(e.seconds + 5) # Wait and add buffer\n",
    "            # Consider adding retry logic here or just skipping\n",
    "            print(f\"Retrying {channel_name} after wait...\")\n",
    "            # You might want to re-add the channel to the *end* of the list to try later\n",
    "            # channel_list.append(channel_name) # Be careful not to create infinite loops\n",
    "            skipped_channels.append(f\"{channel_name} (FloodWait - try later)\")\n",
    "        except errors.AuthKeyError as e:\n",
    "             print(f\"Authentication error for {channel_name}: {e}. Session might be invalid. Stopping.\")\n",
    "             # You might need to re-authenticate or delete the session file and restart.\n",
    "             raise # Stop execution\n",
    "        except Exception as e:\n",
    "            # Catch other potential errors like network issues, timeouts, etc.\n",
    "            import traceback\n",
    "            print(f\"An unexpected error occurred with channel '{channel_name}': {type(e).__name__} - {str(e)}\")\n",
    "            # print(traceback.format_exc()) # Uncomment for detailed traceback\n",
    "            skipped_channels.append(f\"{channel_name} (Error: {type(e).__name__})\")\n",
    "\n",
    "    print(f\"\\n--- Scraping Complete ---\")\n",
    "    print(f\"Successfully processed {processed_channels} channel(s).\")\n",
    "\n",
    "    # Print skipped channels at the end\n",
    "    if skipped_channels:\n",
    "        print(\"\\nSkipped Channels/Errors:\")\n",
    "        for channel_info in skipped_channels:\n",
    "            print(f\"- {channel_info}\")\n",
    "    else:\n",
    "        print(\"\\nNo channels were skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Execute Scraping Process\n",
    "\n",
    "Run the scraping function defined above. This will iterate through the loaded channels and perform the scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the client is connected before starting the main scraping task\n",
    "async def run_scraper():\n",
    "    if not channels: \n",
    "        print(\"No channels loaded. Skipping scraping process.\")\n",
    "        return\n",
    "        \n",
    "    if not client.is_connected():\n",
    "        print(\"Client is not connected. Trying to authenticate again.\")\n",
    "        await authenticate_client()\n",
    "        if not client.is_connected():\n",
    "             print(\"Failed to connect/authenticate client. Aborting scrape.\")\n",
    "             return\n",
    "    \n",
    "    print(\"\\nStarting the scraping process...\")\n",
    "    await scrape_channels(client, channels, output_dir)\n",
    "    print(\"Scraping process finished.\")\n",
    "\n",
    "# Execute the main scraping task\n",
    "# Again, use await directly if your environment supports top-level await.\n",
    "# Otherwise, use asyncio.run() if needed in a pure Python script context.\n",
    "await run_scraper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Disconnect Client\n",
    "\n",
    "It's good practice to disconnect the client when you're finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def disconnect_client():\n",
    "    if client.is_connected():\n",
    "        print(\"\\nDisconnecting the client...\")\n",
    "        await client.disconnect()\n",
    "        print(\"Client disconnected.\")\n",
    "    else:\n",
    "        print(\"\\nClient is already disconnected.\")\n",
    "\n",
    "# Disconnect the client\n",
    "await disconnect_client()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
