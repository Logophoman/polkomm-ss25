{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment-Analyse von TikTok-Kommentaren\n",
    "\n",
    "Dieses Notebook führt eine Sentiment-Analyse (Stimmungsanalyse) für Kommentare durch, die von einer TikTok-Video-Seite mit einem Selenium-Skript gesammelt und in einer JSON-Datei gespeichert wurden.\n",
    "\n",
    "**Ziel:** Die vorherrschende Stimmung (positiv, negativ, neutral) in den Kommentaren zu einem bestimmten TikTok-Video zu ermitteln.\n",
    "\n",
    "**Verwendetes Modell:** Wir nutzen das multilinguale Sentiment-Analyse-Modell `tabularisai/multilingual-sentiment-analysis` von Hugging Face. Dieses Modell kann Kommentare in verschiedenen Sprachen analysieren, ist aber möglicherweise weniger präzise für eine spezifische Sprache als ein dediziertes Modell für diese Sprache.\n",
    "\n",
    "**Wichtig:** Dieses Notebook dient zu Demonstrations- und Lernzwecken. Die Ergebnisse einer automatisierten Sentiment-Analyse sollten stets mit Vorsicht interpretiert werden, da Kontext, Ironie und Sarkasmus oft schwer zu erfassen sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vorbereitung: Bibliotheken installieren und JSON-Datei hochladen\n",
    "\n",
    "Zuerst installieren wir die notwendigen Python-Bibliotheken. Anschließend müssen Sie die JSON-Datei, die von Ihrem TikTok-Scraper generiert wurde (z.B. `tiktok_data_VIDEOID.json`), in das Arbeitsverzeichnis dieses Colab-Notebooks hochladen.\n",
    "\n",
    "**Anleitung zum Hochladen:**\n",
    "1. Klicken Sie auf das Ordner-Symbol in der linken Seitenleiste von Colab.\n",
    "2. Klicken Sie auf das \"Hochladen\"-Symbol (Pfeil nach oben) und wählen Sie Ihre JSON-Datei aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installiere die 'transformers' Bibliothek für die Sentiment-Analyse,\n",
    "# 'pandas' für die Datenverarbeitung und 'matplotlib' sowie 'seaborn' für Visualisierungen.\n",
    "!pip install transformers[sentencepiece] pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiere benötigte Bibliotheken\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import re # Für die Like-Konvertierung\n",
    "\n",
    "print('Bibliotheken erfolgreich importiert.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. JSON-Datei laden und Kommentare extrahieren\n",
    "\n",
    "Geben Sie hier den Namen Ihrer hochgeladenen JSON-Datei an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BITTE DEN DATEINAMEN ANPASSEN, falls Ihre Datei anders heißt!\n",
    "json_filename = 'tiktok_data_7500353799500926230.json' # Beispielname, bitte an Ihre Datei anpassen\n",
    "\n",
    "try:\n",
    "    with open(json_filename, 'r', encoding='utf-8') as f:\n",
    "        video_data_raw = json.load(f)\n",
    "    print(f'JSON-Datei \"{json_filename}\" erfolgreich geladen.')\n",
    "    \n",
    "    # Kommentare extrahieren und in einen Pandas DataFrame umwandeln\n",
    "    if 'comments' in video_data_raw and isinstance(video_data_raw['comments'], list) and video_data_raw['comments']:\n",
    "        df_comments = pd.DataFrame(video_data_raw['comments'])\n",
    "        print(f'Anzahl der Kommentare: {len(df_comments)}')\n",
    "        print(f'Spalten im Kommentar-DataFrame: {df_comments.columns.tolist()}')\n",
    "        print(\"\\nErste paar Kommentare zur Überprüfung:\")\n",
    "        display(df_comments.head()) # display() für schönere Ausgabe in Colab\n",
    "    else:\n",
    "        print(\"Keine Kommentare in der JSON-Datei gefunden oder die Kommentarliste ist leer.\")\n",
    "        df_comments = pd.DataFrame() # Leerer DataFrame, falls keine Kommentare\n",
    "except FileNotFoundError:\n",
    "    print(f\"FEHLER: Die Datei '{json_filename}' wurde nicht gefunden. Bitte laden Sie sie hoch und überprüfen Sie den Namen.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"FEHLER: Die Datei '{json_filename}' ist keine valide JSON-Datei. Bitte überprüfen Sie den Inhalt.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ein Fehler ist beim Laden oder Verarbeiten der JSON-Datei aufgetreten: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Datenbereinigung und -vorbereitung\n",
    "\n",
    "Wir bereinigen die Kommentartexte leicht und konvertieren die Like-Zahlen in numerische Werte, falls vorhanden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_like_count(like_str):\n",
    "    \"\"\"Konvertiert Like-Angaben wie '1.2K' oder '1M' in Zahlen.\"\"\"\n",
    "    if isinstance(like_str, (int, float)):\n",
    "        return int(like_str)\n",
    "    if pd.isna(like_str) or not isinstance(like_str, str):\n",
    "        return 0\n",
    "    \n",
    "    like_str_cleaned = like_str.lower().strip().replace(',', '.') # Ersetze Komma durch Punkt für Floats\n",
    "    if 'k' in like_str_cleaned:\n",
    "        return int(float(like_str_cleaned.replace('k', '')) * 1000)\n",
    "    elif 'm' in like_str_cleaned:\n",
    "        return int(float(like_str_cleaned.replace('m', '')) * 1000000)\n",
    "    elif like_str_cleaned.replace('.', '', 1).isdigit(): # Erlaube einen Punkt für Dezimalzahlen (obwohl bei Likes selten)\n",
    "        return int(float(like_str_cleaned))\n",
    "    return 0 # Fallback für unbekannte Formate oder 'N/A'\n",
    "\n",
    "if 'df_comments' in locals() and not df_comments.empty:\n",
    "    # Fehlende Texte durch leere Strings ersetzen (wichtig für die Pipeline)\n",
    "    df_comments['text'] = df_comments['text'].fillna('').astype(str)\n",
    "    \n",
    "    # Like-Zahlen konvertieren\n",
    "    if 'likes' in df_comments.columns:\n",
    "        df_comments['likes_numeric'] = df_comments['likes'].apply(convert_like_count)\n",
    "        print(\"\\nLikes konvertiert (Beispiel):\")\n",
    "        display(df_comments[['likes', 'likes_numeric']].head())\n",
    "    else:\n",
    "        print(\"Spalte 'likes' nicht im DataFrame gefunden. Setze 'likes_numeric' auf 0.\")\n",
    "        df_comments['likes_numeric'] = 0\n",
    "        \n",
    "    # Entferne Kommentare ohne Text, falls welche durchgerutscht sind\n",
    "    initial_comment_count = len(df_comments)\n",
    "    df_comments = df_comments[df_comments['text'].str.strip() != '']\n",
    "    print(f\"Anzahl Kommentare vor Entfernung leerer Texte: {initial_comment_count}\")\n",
    "    print(f\"Anzahl Kommentare nach Entfernung leerer Texte: {len(df_comments)}\")\n",
    "else:\n",
    "    print(\"Kommentar-DataFrame ist leer oder nicht geladen. Überspringe Datenbereinigung.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialisierung der Sentiment-Analyse Pipeline\n",
    "\n",
    "Wir laden das vortrainierte multilinguale Modell. Dies kann beim ersten Mal einige Minuten dauern, da das Modell (ca. 1-2 GB) heruntergeladen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisiere die Sentiment-Analyse Pipeline\n",
    "print('Initialisiere multilinguale Sentiment-Analyse Pipeline... Dies kann einen Moment dauern.')\n",
    "try:\n",
    "    sentiment_analyzer = pipeline(\n",
    "        task='sentiment-analysis', \n",
    "        model='tabularisai/multilingual-sentiment-analysis', \n",
    "        # device=0 # Für GPU-Nutzung entkommentieren (falls CUDA verfügbar ist)\n",
    "    )\n",
    "    print('Sentiment-Analyse Pipeline erfolgreich initialisiert.')\n",
    "except Exception as e:\n",
    "    print(f\"Fehler bei der Initialisierung der Pipeline: {e}\")\n",
    "    print(\"Stellen Sie sicher, dass eine Internetverbindung besteht und die 'transformers'-Bibliothek korrekt installiert ist.\")\n",
    "    sentiment_analyzer = None # Setze auf None, damit spätere Zellen nicht fehlschlagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sentiment-Analyse der Kommentare durchführen\n",
    "\n",
    "Nun wenden wir das initialisierte Modell auf jeden Kommentartext an. Da dies für viele Kommentare dauern kann, geben wir alle 50 Kommentare eine Statusmeldung aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_for_comment(text_to_analyze):\n",
    "    \"\"\"Analysiert den Sentiment eines einzelnen Kommentartextes.\"\"\"\n",
    "    if not text_to_analyze or pd.isna(text_to_analyze):\n",
    "        return {'label': 'NO_TEXT', 'score': 0.0}\n",
    "    try:\n",
    "        # Das Modell hat eine maximale Sequenzlänge (oft 512 Tokens).\n",
    "        # TikTok Kommentare sind meist kurz, aber zur Sicherheit kürzen wir.\n",
    "        # Die Pipeline sollte dies intern handhaben, aber explizit ist sicherer.\n",
    "        max_char_length = 400 # Zeichen, nicht Tokens, für eine einfache, sichere Kürzung\n",
    "        truncated_text = text_to_analyze[:max_char_length]\n",
    "        \n",
    "        result = sentiment_analyzer(truncated_text)\n",
    "        if result and isinstance(result, list):\n",
    "            # Das Modell 'tabularisai/multilingual-sentiment-analysis' gibt Labels wie 'positive', 'negative', 'neutral' zurück.\n",
    "            return result[0] \n",
    "        else:\n",
    "            return {'label': 'ERROR_PARSING_RESULT', 'score': 0.0}\n",
    "    except Exception as e:\n",
    "        # print(f\"Fehler bei der Analyse von Text: '{str(text_to_analyze)[:50]}...': {e}\") # Für Debugging\n",
    "        return {'label': 'ERROR_ANALYSIS', 'score': 0.0}\n",
    "\n",
    "if 'df_comments' in locals() and not df_comments.empty and 'sentiment_analyzer' in locals() and sentiment_analyzer is not None:\n",
    "    print(f\"Führe Sentiment-Analyse für {len(df_comments)} Kommentare durch...\")\n",
    "    \n",
    "    sentiment_labels = []\n",
    "    sentiment_scores = []\n",
    "    \n",
    "    start_time_analysis = time.time()\n",
    "    \n",
    "    # Iteriere über die Zeilen des DataFrames\n",
    "    # Für eine schnelle Demo kann man .head(X) verwenden, z.B. df_comments.head(50).iterrows()\n",
    "    for index, row in df_comments.iterrows(): \n",
    "        comment_text = row['text']\n",
    "        \n",
    "        if not comment_text.strip():\n",
    "            sentiment_result = {'label': 'NO_TEXT', 'score': 0.0}\n",
    "        else:\n",
    "            sentiment_result = analyze_sentiment_for_comment(comment_text)\n",
    "        \n",
    "        sentiment_labels.append(sentiment_result['label'])\n",
    "        sentiment_scores.append(sentiment_result.get('score', 0.0))\n",
    "        \n",
    "        if (index + 1) % 50 == 0:\n",
    "            elapsed_time = time.time() - start_time_analysis\n",
    "            print(f\"--- {index + 1}/{len(df_comments)} Kommentare verarbeitet in {elapsed_time:.2f} Sekunden ---\")\n",
    "\n",
    "    # Füge die Ergebnisse als neue Spalten zum DataFrame hinzu\n",
    "    df_comments['sentiment_label'] = sentiment_labels\n",
    "    df_comments['sentiment_score'] = sentiment_scores\n",
    "    \n",
    "    end_time_analysis = time.time()\n",
    "    print(f'\\nSentiment-Analyse für {len(df_comments)} Kommentare abgeschlossen in {(end_time_analysis - start_time_analysis):.2f} Sekunden.')\n",
    "    \n",
    "    print(\"\\nDataFrame mit Sentiment-Ergebnissen (erste Zeilen):\")\n",
    "    display(df_comments[['author', 'text', 'likes_numeric', 'sentiment_label', 'sentiment_score']].head())\n",
    "    \n",
    "    # Speichere den DataFrame mit den Sentiment-Ergebnissen (optional)\n",
    "    # Erzeugt einen neuen Dateinamen basierend auf dem Original\n",
    "    base_name = json_filename.rsplit('.', 1)[0]\n",
    "    output_filename_csv = f\"{base_name}_mit_sentiment.csv\"\n",
    "    output_filename_excel = f\"{base_name}_mit_sentiment.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        df_comments.to_csv(output_filename_csv, index=False, encoding='utf-8-sig') # utf-8-sig für bessere Excel-Kompatibilität mit Umlauten\n",
    "        print(f\"\\nDaten mit Sentiment-Analyse gespeichert in CSV: {output_filename_csv}\")\n",
    "        # df_comments.to_excel(output_filename_excel, index=False) \n",
    "        # print(f\"Daten mit Sentiment-Analyse gespeichert in Excel: {output_filename_excel}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Speichern der Ergebnisse: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Voraussetzungen für die Analyse (DataFrame, Pipeline) nicht erfüllt. Analyse wird übersprungen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Auswertung und Visualisierung der Ergebnisse\n",
    "\n",
    "Nachdem die Sentiment-Analyse durchgeführt wurde, können wir uns die Verteilung der Sentiments ansehen und einige einfache Auswertungen vornehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_comments' in locals() and not df_comments.empty and 'sentiment_label' in df_comments.columns:\n",
    "    print(\"\\n--- Auswertung der Sentiment-Ergebnisse ---\")\n",
    "    \n",
    "    # 1. Verteilung der Sentiment-Labels\n",
    "    sentiment_counts = df_comments['sentiment_label'].value_counts()\n",
    "    sentiment_percentages = df_comments['sentiment_label'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"\\nVerteilung der Sentiment-Labels:\")\n",
    "    print(sentiment_counts)\n",
    "    print(\"\\nProzentuale Verteilung der Sentiment-Labels:\")\n",
    "    print(sentiment_percentages.round(2).astype(str) + ' %')\n",
    "    \n",
    "    # 2. Visualisierung der Sentiment-Verteilung\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(data=df_comments, x='sentiment_label', order=sentiment_counts.index, palette='viridis')\n",
    "    plt.title('Verteilung der Sentiment-Labels in den Kommentaren', fontsize=15)\n",
    "    plt.xlabel('Sentiment Label', fontsize=12)\n",
    "    plt.ylabel('Anzahl der Kommentare', fontsize=12)\n",
    "    plt.xticks(rotation=0)\n",
    "    # Füge die Anzahl über den Balken hinzu\n",
    "    for i, count in enumerate(sentiment_counts):\n",
    "        plt.text(i, count + (0.01 * len(df_comments)), str(count), ha='center', va='bottom', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Durchschnittlicher Sentiment-Score pro Label (falls Scores aussagekräftig sind)\n",
    "    #    Das Modell 'tabularisai/multilingual-sentiment-analysis' gibt diskrete Labels aus (positive, negative, neutral).\n",
    "    #    Der Score ist die Konfidenz des Modells für dieses Label. \n",
    "    #    Eine Aggregation der Scores ist hier weniger sinnvoll als bei Modellen, die einen kontinuierlichen Score von -1 bis 1 liefern.\n",
    "    #    Wir können aber die durchschnittliche Konfidenz pro Label anzeigen.\n",
    "    if 'sentiment_score' in df_comments.columns:\n",
    "        avg_confidence = df_comments.groupby('sentiment_label')['sentiment_score'].mean().sort_values(ascending=False)\n",
    "        print(\"\\nDurchschnittliche Konfidenz (Score) pro Sentiment-Label:\")\n",
    "        print(avg_confidence.round(4))\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        avg_confidence.plot(kind='bar', color=sns.color_palette('coolwarm', len(avg_confidence)))\n",
    "        plt.title('Durchschnittliche Konfidenz pro Sentiment-Label', fontsize=15)\n",
    "        plt.xlabel('Sentiment Label', fontsize=12)\n",
    "        plt.ylabel('Durchschnittlicher Score (Konfidenz)', fontsize=12)\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.ylim(0, 1) # Scores sind typischerweise zwischen 0 und 1\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    # 4. Beispiele für Kommentare pro Sentiment-Kategorie\n",
    "    print(\"\\nBeispiel-Kommentare pro Sentiment-Kategorie:\")\n",
    "    for label in sentiment_counts.index:\n",
    "        print(f\"\\n--- {label.upper()} Kommentare (bis zu 3 Beispiele) ---\")\n",
    "        sample_comments = df_comments[df_comments['sentiment_label'] == label]['text'].sample(min(3, len(df_comments[df_comments['sentiment_label'] == label]))).tolist()\n",
    "        for i, comment_text in enumerate(sample_comments):\n",
    "            print(f\"{i+1}. {comment_text[:150]}{'...' if len(comment_text) > 150 else ''}\") # Kommentare kürzen\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame oder Sentiment-Spalten nicht vorhanden für die detaillierte Auswertung.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Mögliche Weiterführungen und Limitationen\n",
    "\n",
    "### Weiterführende Analysen:\n",
    "- **Sentiment im Zeitverlauf:** Wenn Ihre Daten Zeitstempel für Kommentare hätten (z.B. genaue Upload-Zeiten statt nur relative Angaben wie \"Vor 2 T.\"), könnten Sie analysieren, wie sich das Sentiment über die Zeit entwickelt hat.\n",
    "- **Sentiment in Relation zu Likes:** Untersuchen, ob Kommentare mit bestimmtem Sentiment tendenziell mehr (oder weniger) Likes erhalten. Hierfür müssten die Like-Zahlen der Kommentare zuverlässig erfasst werden.\n",
    "- **Themenmodellierung (Topic Modeling):** Innerhalb der positiven/negativen Kommentare könnten Sie versuchen, die Hauptthemen zu identifizieren (z.B. mit LDA oder BERTopic).\n",
    "- **Wortwolken:** Erstellen Sie Wortwolken für jede Sentiment-Kategorie, um häufige Begriffe zu visualisieren.\n",
    "- **Vergleich zwischen Videos:** Führen Sie diese Analyse für mehrere Videos durch und vergleichen Sie die Sentiment-Verteilungen.\n",
    "\n",
    "### Limitationen:\n",
    "- **Genauigkeit des Modells:** Kein Sentiment-Analyse-Modell ist perfekt. Besonders bei subtilen Äußerungen, Ironie, Sarkasmus oder sehr kontextabhängigen Aussagen kann es zu Fehlklassifikationen kommen.\n",
    "- **Sprachliche Nuancen:** Emojis, Umgangssprache, Dialekte und kulturelle Referenzen können die Analyse erschweren.\n",
    "- **Mehrdeutigkeit:** Manche Kommentare sind objektiv schwer einzuordnen.\n",
    "- **Sampling Bias des Scrapings:** Die gescrapten Kommentare repräsentieren möglicherweise nicht alle Kommentare, die jemals zu dem Video gepostet wurden (z.B. wenn nicht alle geladen werden konnten oder einige später gelöscht wurden).\n",
    "- **'Likes' für Kommentare:** Die im Beispiel-JSON gezeigten \"likes: 0\" deuten darauf hin, dass die Like-Zahlen für Kommentare im Scraping-Prozess entweder nicht erfasst wurden oder tatsächlich 0 waren. Für eine Analyse der Korrelation zwischen Sentiment und Likes wären valide Like-Zahlen für die Kommentare selbst notwendig.\n",
    "\n",
    "**Empfehlung:** Betrachten Sie die Ergebnisse als ersten Indikator und ergänzen Sie sie idealerweise durch qualitative Analysen ausgewählter Kommentare, um ein tiefergehendes Verständnis zu gewinnen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  },
  "colab": {
    "provenance": [],
    "collapsed_sections": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}